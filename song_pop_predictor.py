# -*- coding: utf-8 -*-
"""song_pop_predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K17sl2IQwifHQoMDoLLjH44rJhD1-RYk
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from tqdm import tqdm
tqdm.pandas()
import seaborn as sns
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/Shareddrives/DEEP2021/Notebooks/spotify_data.csv')

df.shape

df.head()

df.columns

df.info()

"""Let's Perform some Data Cleaning to make our data easier to work with

"""

#The specific ID of any given song is information we won't be needing so we can remove it
clean_data = df.drop(columns= ["id"])
#We also convert the millisecond length of a song to minute length to make results more interpretable
clean_data['duration_min'] = clean_data['duration_ms']*0.0000166667

#Next, let's look at the distribution of values in each relevant column
    #we notice that there are zero values inside of entries, but zero values don't make sense in the context of our data
    #so we want to remove these entries with invalid data
clean_data = clean_data.loc[clean_data['tempo']>0]
clean_data = clean_data.loc[clean_data['valence']>0]
clean_data = clean_data.loc[clean_data['speechiness']>0]
clean_data = clean_data.loc[clean_data['popularity']>0]
clean_data = clean_data.loc[clean_data['danceability']>0]

#Let's reformat the artist tab such that the opening and closing "['" are removed, allowing us to easier search for artists
clean_data["artists"] = clean_data["artists"].apply(lambda x: x[2: -2])

#Reprocessing the release_date column to three seperate columns for year month and date to increase the granularity of our data
clean_data['release_date']= pd.to_datetime(df['release_date'],format='%Y-%m-%d')
clean_data['year']= clean_data['release_date'].dt.year
clean_data['month']= clean_data['release_date'].dt.month
clean_data['day']= clean_data['release_date'].dt.day
clean_data.head()





"""Let's now create some basic visualizations to better understand our data"""

sns.scatterplot(x="danceability", y="energy", data=clean_data)

# seems like there is a very weak, positive, linear relationship
# few outliers, no clusters

#Do "energetic" songs tend to be loud?
energetic_songs_df = clean_data[clean_data["energy"] > .9 ]
energetic_songs_df.head()
#sns.scatterplot(x="energy", y="loudness", data=clean_data)
sns.scatterplot(x="energy", y="loudness", data=energetic_songs_df)

#What is the distribution of loudness in all songs?
#df["Loudness (dB)"].hist()
#df["Energy"].hist()
clean_data["popularity"].hist()
# df["Valence"].hist()

plt.figure(figsize=(10,5))
chart = sns.boxplot(y="valence", data=clean_data)

# continuous_df = clean_data.select_dtypes(include=[np.int64])
# copy_df = clean_data.copy()
# chart = sns.pairplot(data=copy_df)
# chart

plt.figure(figsize=(12, 8))
ax = sns.heatmap(df.corr(), center=0, annot=True, vmin=-1, vmax=1)
ax.plot()

#-what is the average length of all songs?
        #-How has song length changed each year? -plot it
yearly_song_length = clean_data.loc[clean_data['duration_min']<=16, ['popularity', 'year']]
avg_length_by_year = yearly_song_length.groupby('year').mean()

avg_length_by_year.plot(title="average popularity by year");
plt.ylabel("average popularity ")

ax = sns.distplot(clean_data['popularity'])

import plotly.express as px   #importing plotly
#this is a scatter plot of the average danceability of the songs for every popularity rating
  #for example, we can interpret a point on this plot as the average danceability of all the songs with popularity rating: x

  #what does this tell us about the danceability of songs as popularity increases?... any trends?...

  #will try adding a few plots in one slide to the presentation to contextualize the selection of our feature attributes in the model

  #to try with other attributes just rename variable names and replace every occurence of 'danceability' with another attribute
song_popularity = clean_data.groupby('popularity')['danceability'].mean().sort_values(ascending=[False]).reset_index()
song_popularity.head()
fig2 = px.scatter(song_popularity, x="popularity", y="danceability", color="danceability",size='popularity')
fig2.show()

features = ["danceability", "energy", "acousticness", "liveness", "tempo"]

target = clean_data["popularity"]

musicstats_train, musicstats_test, popularity_train, popularity_test = train_test_split(clean_data[features], target, test_size=0.2, random_state=0)

linearmodel = LinearRegression()
linearmodel.fit(musicstats_train, popularity_train)
#linearmodel.score()

popularity_predicted = linearmodel.predict(musicstats_test)

print(mean_squared_error(popularity_test, popularity_predicted))

print(r2_score(popularity_test.array, popularity_predicted))
#print(accuracy_score(popularity_test, popularity_predicted))

print(linearmodel.coef_)

features_KNN = ["danceability", "energy", "acousticness", "liveness", "tempo"]

target_KNN = clean_data["popularity"]

features_train, features_test, pop_train, pop_test = train_test_split(clean_data[features_KNN], target_KNN, test_size = 0.3)

KNN_model = KNeighborsClassifier(n_neighbors = 1)

KNN_model.fit(features_train, pop_train)

def knn_accuracy(pop_test, pop_pred, interval_len):
  new_pop = []
  num_true = 0
  num_false = 0
  for pop_idx in range(0, len(pop_pred)):
    pred_popval = pop_pred[pop_idx]
    pred_popval_lower = pred_popval - interval_len
    pred_popval_upper = pred_popval + interval_len
    actual_popval = pop_test[pop_idx]
    if pred_popval_lower <= actual_popval <= pred_popval_upper:
      new_pop.append(1)
    else:
      new_pop.append(0)
  for val in new_pop:
    if val == 1:
      num_true += 1
    else:
      num_false += 1
  return num_true / len(new_pop)

pop_pred = KNN_model.predict(features_test)

#print(pop_pred.size)
#print(pop_test.size)
#np.around(pop_pred)
#print(pop_pred)
#print(pop_test)
#print(pop_test.array[0])
interval_len = 10
print(knn_accuracy(pop_test.array, pop_pred, interval_len))
#print(accuracy_score(pop_test, pop_pred))
#print(classification_report(pop_test, pop_pred))

